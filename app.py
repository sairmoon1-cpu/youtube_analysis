import streamlit as st
from googleapiclient.discovery import build
import pandas as pd
from collections import Counter
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from io import BytesIO
import base64
from konlpy.tag import Okt
import plotly.express as px
import urllib.request
import os

# --------------------------
# í•œê¸€ í°íŠ¸ ì›¹ì—ì„œ ë‹¤ìš´ë¡œë“œ
# --------------------------
@st.cache_resource
def download_font():
    font_url = "https://github.com/naver/nanumfont/blob/master/ttf/NanumGothic.ttf?raw=true"
    font_path = "/tmp/NanumGothic.ttf"
    if not os.path.exists(font_path):
        urllib.request.urlretrieve(font_url, font_path)
    return font_path

FONT_PATH = download_font()

# ------------------------
# ìœ íŠœë¸Œ ëŒ“ê¸€ ìˆ˜ì§‘
# ------------------------
def get_video_id(url):
    import re
    match = re.search(r"(?:v=|youtu.be/)([a-zA-Z0-9_-]{11})", url)
    return match.group(1) if match else None

def get_comments(video_id, max_results=100):
    api_key = st.secrets["youtube_api_key"]
    youtube = build('youtube', 'v3', developerKey=api_key)
    comments = []

    response = youtube.commentThreads().list(
        part='snippet',
        videoId=video_id,
        maxResults=min(max_results, 100),
        textFormat='plainText'
    ).execute()

    for item in response['items']:
        comment = item['snippet']['topLevelComment']['snippet']['textDisplay']
        comments.append(comment)

    return comments

# ------------------------
# ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
# ------------------------
def generate_wordcloud(text_list, font_path):
    text = ' '.join(text_list)
    okt = Okt()
    words = okt.nouns(text)
    word_freq = Counter(words)

    wc = WordCloud(
        font_path=font_path,
        width=800,
        height=400,
        background_color='white'
    ).generate_from_frequencies(word_freq)

    buf = BytesIO()
    plt.figure(figsize=(10, 5))
    plt.imshow(wc, interpolation='bilinear')
    plt.axis("off")
    plt.tight_layout()
    plt.savefig(buf, format='png')
    buf.seek(0)
    encoded = base64.b64encode(buf.read()).decode()
    return f"data:image/png;base64,{encoded}"

# ------------------------
# Streamlit App ì‹œì‘
# ------------------------
st.set_page_config(page_title="YouTube ëŒ“ê¸€ í‚¤ì›Œë“œ ë¶„ì„ê¸°", layout="wide")
st.title("ğŸ’¬ YouTube ëŒ“ê¸€ í‚¤ì›Œë“œ ë¶„ì„ê¸° (í•œê¸€ ì§€ì›)")

url = st.text_input("ğŸ¥ ë¶„ì„í•  ìœ íŠœë¸Œ ì˜ìƒ URLì„ ì…ë ¥í•˜ì„¸ìš”")

if st.button("ë¶„ì„ ì‹œì‘") and url:
    video_id = get_video_id(url)
    if not video_id:
        st.error("ìœ íš¨í•œ ìœ íŠœë¸Œ URLì´ ì•„ë‹™ë‹ˆë‹¤.")
    else:
        with st.spinner("ëŒ“ê¸€ì„ ìˆ˜ì§‘í•˜ê³  ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            comments = get_comments(video_id)
            if not comments:
                st.warning("ëŒ“ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.success(f"{len(comments)}ê°œì˜ ëŒ“ê¸€ì„ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
                df = pd.DataFrame({'ëŒ“ê¸€': comments})

                # ë‹¨ì–´ ë¹ˆë„ ë¶„ì„
                all_text = ' '.join(df['ëŒ“ê¸€'])
                okt = Okt()
                nouns = okt.nouns(all_text)
                word_freq = Counter(nouns)
                top_words = word_freq.most_common(20)
                word_df = pd.DataFrame(top_words, columns=['ë‹¨ì–´', 'ë¹ˆë„'])

                # ì‹œê°í™”
                st.subheader("ğŸ“Š ë‹¨ì–´ ë¹ˆë„ Top 20")
                fig = px.bar(word_df, x='ë‹¨ì–´', y='ë¹ˆë„', title='ë‹¨ì–´ ë¹ˆë„ ë§‰ëŒ€ê·¸ë˜í”„')
                st.plotly_chart(fig)

                st.subheader("â˜ï¸ ì›Œë“œí´ë¼ìš°ë“œ")
                img_uri = generate_wordcloud(df['ëŒ“ê¸€'].tolist(), FONT_PATH)
                st.markdown(f'<img src="{img_uri}" width="100%">', unsafe_allow_html=True)
